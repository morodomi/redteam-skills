# Cycle: dast-crawler

| Item | Value |
|------|-------|
| Issue | #42 |
| Phase | COMMIT |
| Created | 2026-01-15 11:57 |

## Environment

| Tool | Version |
|------|---------|
| Node.js | v22.17.0 |

## Goal

PlaywrightベースのURL自動発見エージェントを作成。静的解析では見つからない動的エンドポイントを検出。

## Background

From Issue #42:
- Playwright MCPでブラウザ操作
- JSで動的生成されるURLを発見
- フォーム・リンクを自動探索
- 発見URLをdynamic-verifierに渡す

## Scope

From Issue #42:
- [ ] dast-crawler エージェント作成
- [ ] Playwright MCP連携
- [ ] URL/フォーム発見機能
- [ ] 出力形式定義

## PLAN

### Background

recon-agentは静的解析でエンドポイントを発見するが、SPAやAjax通信のエンドポイントは検出できない。
dast-crawlerはPlaywrightでブラウザをシミュレートし、動的に生成されるURLを発見する。

### Design

#### エージェント構造

```yaml
name: dast-crawler
description: PlaywrightベースのURL自動発見エージェント
allowed-tools: Read, Bash, mcp__playwright__*
```

#### Detection Targets

| Target | Description | Method |
|--------|-------------|--------|
| URL Discovery | リンク、ボタン、ナビゲーション | DOM解析、クリックイベント |
| Form Discovery | フォーム要素、action/method | form要素解析 |
| Ajax Endpoints | XHR/Fetch API呼び出し | Network監視 |

#### Crawl Strategy

1. **Page Navigation**: リンクを辿って新規ページを発見
2. **Form Detection**: フォーム要素とフィールドを抽出
3. **Network Monitoring**: XHR/Fetchリクエストを監視
4. **SPA Support**: ハッシュ変更、History API監視

#### Safety Measures

| Rule | Description |
|------|-------------|
| Same-Origin | ベースURLと同一オリジンのみクロール |
| Max Pages | 最大50ページ |
| Max Depth | 最大5階層 |
| Timeout | 30秒/ページ |
| Read-Only | GET/HEADのみ、フォーム送信なし |

#### Output Format

```json
{
  "metadata": {
    "scan_id": "<uuid>",
    "scanned_at": "<timestamp>",
    "base_url": "http://localhost:8000"
  },
  "discovered_urls": [
    {
      "url": "/api/v1/users",
      "method": "GET",
      "source": "xhr"
    }
  ],
  "forms": [
    {
      "action": "/login",
      "method": "POST",
      "fields": ["username", "password"]
    }
  ],
  "summary": {
    "pages_crawled": 10,
    "urls_found": 25,
    "forms_found": 3
  }
}
```

### Files

```
plugins/redteam-core/agents/
└── dast-crawler.md    # 新規

scripts/
└── test-dast-crawler.sh  # 新規
```

## Test List

### TODO

#### エージェント構造
- [ ] TC-01: frontmatterにname: dast-crawlerがある
- [ ] TC-02: frontmatterにallowed-toolsがある
- [ ] TC-03: Detection Targetsセクションがある

#### Playwright連携
- [ ] TC-04: Playwright MCP Integrationセクションがある
- [ ] TC-05: Crawl Strategyセクションがある

#### Output Format
- [ ] TC-06: Output Formatにdiscovered_urlsがある
- [ ] TC-07: Output Formatにformsがある

#### 安全対策
- [ ] TC-08: Safety Measuresセクションがある

### WIP

(なし)

### DONE

- [x] TC-01: frontmatterにname: dast-crawlerがある
- [x] TC-02: frontmatterにallowed-toolsがある
- [x] TC-03: Detection Targetsセクションがある
- [x] TC-04: Playwright MCP Integrationセクションがある
- [x] TC-05: Crawl Strategyセクションがある
- [x] TC-06: Output Formatにdiscovered_urlsがある
- [x] TC-07: Output Formatにformsがある
- [x] TC-08: Safety Measuresセクションがある

## REVIEW

### Quality Gate Results

| Reviewer | Score | Judgment |
|----------|-------|----------|
| correctness | 25 | PASS |
| performance | 35 | PASS |
| security | 25 | PASS |
| guidelines | 15 | PASS |

**Max Score: 35 → PASS**

### Notes

- Deduplication Strategy追加で無限ループ防止
- URL normalization実装で重複クロール防止
- Playwright MCP evaluate()の用途明記
- Read-Only vs POST発見の区別を明記

## Notes

- v4.1 マイルストーン
- 関連: #43 attack-scenario（dast-crawlerの結果を使用）
