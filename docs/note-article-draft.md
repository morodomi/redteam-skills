# AIに書かせたコードを、AIに攻撃させたら穴だらけだった

## TL;DR

Claude Codeで作ったコードを、Claude Codeで脆弱性診断するプラグインを作った。`/security-scan` の一言で、AIが勝手にSQLインジェクションやXSSを探してくる。そして容赦なく指摘してくる。お前が書いたコードなのに。

GitHub: https://github.com/morodomi/redteam-skills

---

## 守りを固めたら、攻めたくなった

前回、tdd-skillsというプラグインを作った。AIに「テストを先に書け」と躾けるやつだ。

おかげでコード品質は上がった。テストは書かれるようになった。CIも通る。カバレッジも90%超え。めでたしめでたし。

...で、セキュリティは？

「それは後で」

エンジニアが最も得意な言い訳である。

テストが通る。型チェックも通る。リンターも通る。コードレビューも通った。

でも、そのコード、SQLインジェクションできるんだけど。

---

## 脆弱性診断は「後でやる」の墓場

セキュリティ監査の現実を整理しよう。

**商用ツール**: 高い。年間ライセンス何十万。稟議を通す頃にはリリースが終わっている。

**OSSツール**: 設定が面倒。YAML地獄。誤検知の嵐。「これ本当に脆弱性？」の確認作業で1日が終わる。

**手動診断**: 時間がない。そもそもやり方がわからない。「SQLインジェクション 確認方法」でググる時点で負けている。

**外部委託**: 高い。そしてスケジュールが合わない。「来月なら空いてます」。リリースは来週だ。

結果、セキュリティは後回しになる。

リリースが優先。機能追加が優先。バグ修正が優先。パフォーマンス改善が優先。

セキュリティは...まあ、今のところ何も起きてないし。

「脆弱性診断は次のスプリントで」

そう言って3スプリント経った。いや、3ヶ月かもしれない。

---

## 「何も起きてない」という幻想

「今のところ何も起きてない」

これが一番危険な言葉だ。

何も起きてないんじゃない。気づいてないだけだ。

攻撃者はログを残さない。成功した攻撃は静かに行われる。データは静かに抜かれる。

「うちは大丈夫」

そう思っていた会社が、ある日ニュースになる。

でも、わかっている。わかっているけど、目の前のタスクが優先される。締め切りが優先される。

セキュリティは「重要だけど緊急じゃない」の代表格だ。

そして「緊急じゃない」は「やらない」と同義である。

---

## AIに攻撃者を演じさせる

ふと思った。

AIにコードを書かせている。AIにテストを書かせている。AIにレビューさせている。AIにドキュメントを書かせている。

じゃあ、AIに攻撃させればいいのでは？

AIは疲れない。AIは「面倒くさい」と思わない。AIは「まあいいか」と妥協しない。

人間が後回しにすることを、AIに押し付ければいい。

Blue Team（防御）があるなら、Red Team（攻撃）もあっていい。

tdd-skillsが「守り」なら、redteam-skillsは「攻め」だ。

同じClaude。同じAI。でも役割が違う。

守りのAIは「テスト書いて」と言う。
攻めのAIは「ここ、SQLインジェクションできるよ」と言う。

人格が分裂している？いや、これが正しい使い方だ。

---

## 構造は単純

redteam-skillsの構造は単純だ。

1. **RECON**: コードを読んで、エンドポイントを列挙する
2. **SCAN**: 各エンドポイントに対して、脆弱性パターンを探す
3. **REPORT**: 見つかった脆弱性をレポートする

やっていることは、人間のペネトレーションテスターと同じだ。

違いは、AIが勝手にやってくれること。そして、文句を言わないこと。

人間に「このコード全部読んで、脆弱性探して」と頼んだら嫌な顔をされる。

AIは嫌な顔をしない。黙々とコードを読む。黙々とパターンマッチングする。黙々とレポートを出す。

最高の部下だ。給料も要らない。

---

## 実際に使ってみた

```bash
/security-scan
```

これだけ。

AIが勝手にコードを読み始める。エンドポイントを列挙する。フレームワークを検出する。

「Laravelですね。ルーティングを解析します」

勝手にやってくれる。

数分後、レポートが出てきた。

```json
{
  "vulnerabilities": {
    "total": 15,
    "critical": 2,
    "high": 5,
    "medium": 8
  }
}
```

待て待て待て。

15件？Critical 2件？

「SQLI-001: User input directly concatenated into SQL query」
「XSS-003: User input reflected without escaping」
「CSRF-001: No CSRF token in form」

お前が書いたコードだろ。

いや、正確には「AIに書かせたコード」だ。AIが書いて、AIがレビューして、AIがテストを書いた。そのコードを、AIが攻撃している。

マッチポンプか？

いや、違う。

守りのAIと攻めのAIは、見ている観点が違う。

守りのAIは「正しく動くか」を見ている。
攻めのAIは「壊せるか」を見ている。

テストが通ることと、セキュアであることは、別の話だ。

---

## AIは容赦しない

人間のコードレビューには「空気を読む」がある。

「ここ、ちょっと気になるけど...まあ動いてるし」
「指摘しすぎると嫌われるし」
「本人も忙しそうだし」
「前回指摘したら不機嫌になったし」
「そもそも自分もやってるし」

人間関係というフィルターがかかる。

AIにはそれがない。

「このコード、XSSの脆弱性があります」
「ここ、CSRFトークンがありません」
「これ、パストラバーサルできます」
「このハッシュ関数、弱いです」
「デバッグモードが有効です」

空気？読まない。忖度？しない。遠慮？知らない。

ある意味、最高のセキュリティレビュアーだ。

人間関係を気にしなくていい。「言いにくいこと」がない。

全部言う。容赦なく言う。

---

## 指摘された側の気持ち

正直、最初は腹が立った。

「お前が書いたコードだろ」と思った。

でも、冷静に考えると、指摘は正しい。

$_GET['id'] をそのままSQLに突っ込んでいる。これは脆弱性だ。言い訳できない。

AIに書かせたコードだから、AIの責任？

違う。承認したのは人間だ。「いい感じ」と思ってマージしたのは人間だ。

AIは提案しただけ。最終判断は人間。

つまり、責任は人間にある。

そして、その人間のミスを、別のAIが指摘している。

なんだこの構図。

---

## 攻撃者の視点

redteam-skillsを作って、気づいたことがある。

攻撃者の視点は、開発者の視点と全く違う。

開発者は「正しく動くか」を考える。
攻撃者は「どう壊すか」を考える。

開発者は「想定されたユーザー」を想像する。
攻撃者は「悪意のあるユーザー」を想像する。

開発者は「こう使われるはず」と思う。
攻撃者は「こう悪用できる」と思う。

視点が180度違う。

だから、開発者だけでセキュリティを担保するのは難しい。自分のコードの穴は、自分では見えない。

攻撃者の視点を持つ誰か（または何か）が必要だ。

それがRed Teamであり、ペネトレーションテスターであり、このプラグインだ。

---

## Blue TeamとRed Team

tdd-skillsとredteam-skillsを両方使うようになって、気づいたことがある。

守りだけでは不十分だ。

テストが通っても、セキュリティホールはある。
CIが通っても、脆弱性はある。
コードレビューを通っても、攻撃可能な箇所はある。
型チェックが通っても、インジェクションはできる。

攻撃者の視点がなければ、守りは完成しない。

Blue Teamが「正しく動くか」を確認する。
Red Teamが「壊せるか」を確認する。

両方あって、初めてバランスが取れる。

守りだけのチームは、穴に気づかない。
攻めだけのチームは、何も作れない。

両方必要だ。

---

## AIの二面性

同じClaude Codeを使って、守りと攻めをやっている。

これは面白い構図だ。

AIは「良いこと」も「悪いこと」もできる。使い方次第だ。

コードを書くこともできれば、コードの穴を探すこともできる。
守ることもできれば、攻めることもできる。

どちらもAIの能力だ。どちらに使うかは、人間が決める。

redteam-skillsは、AIの「攻め」の能力を、「守り」のために使っている。

攻撃手法を知っているからこそ、防御できる。
穴の探し方を知っているからこそ、穴を塞げる。

攻めと守りは表裏一体だ。

---

## 使い方

インストール:
```bash
/plugin marketplace add morodomi/redteam-skills
/plugin install redteam-core@morodomi-redteam-skills
```

スキャン:
```bash
/security-scan
```

動的テスト（ローカルサーバーがある場合）:
```bash
/security-scan --dynamic --target http://localhost:8000
```

動的テスト + XSS検証:
```bash
/security-scan --dynamic --enable-dynamic-xss --target http://localhost:8000
```

検出できる脆弱性:
- SQLインジェクション / コマンドインジェクション
- XSS（Reflected, DOM, Stored）
- CSRF
- 認証バイパス / JWT脆弱性
- パストラバーサル / LFI / RFI
- SSRF
- 弱い暗号化 / デバッグモード
- 不適切な例外処理

OWASP Top 10はカバーしている。

---

## 今後の展望

現状は静的解析が中心だ。コードを読んで、パターンマッチングで脆弱性を探している。

次のステップは、E2Eテストの自動生成。

静的解析で「ここ、XSSの可能性あり」と検出したら、それを検証するPlaywrightのテストコードを自動生成する。

人間は実行するだけ。

「脆弱性の検出」から「脆弱性の検証」まで、全部AIがやる。

人間の仕事は「承認ボタンを押すこと」だけになる。

...また承認ボタンか。

---

## まとめ

AIに攻撃を教えたら、AIは容赦なく攻撃してきた。

それでいい。

セキュリティに「空気を読む」は不要だ。脆弱性は脆弱性。指摘されるべきは指摘されるべき。

人間関係を気にして言えないことを、AIは言ってくれる。

守りのAIと攻めのAI。
tdd-skillsとredteam-skills。
Blue TeamとRed Team。

両方使って、初めて「AIに任せた」と言える気がする。

片方だけでは不十分だ。守りだけでは穴がある。攻めだけでは何も作れない。

両方のAIを従えて、人間は承認ボタンを押す。

...結局、承認ボタンなんだけど。

でも、押すボタンが増えた分、少しはマシになった気がする。

---

**GitHub**: https://github.com/morodomi/redteam-skills
**関連**: [tdd-skills](https://github.com/morodomi/tdd-skills) - 守りのAI
**記事**: [Claude CodeにTDDを強制したら、AIが勝手にテストを書くようになった話](https://note.com/morodomi/n/n5b089a48fe7b)
